# Customer Support Orchestrator

<div align="center">

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)
![LangChain](https://img.shields.io/badge/LangChain-Latest-orange.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**AI-powered customer support system with RAG, conversation memory, intelligent caching, and feedback analytics**

</div>

---

## ğŸ¯ Overview

Production-ready customer support system featuring:

-  **Conversation Memory** - Multi-turn dialogues with context awareness
-  **Query Caching** - Faster responses for repeated questions
-  **Feedback Analytics** - User ratings and improvement insights
-  **Smart Routing** - LangGraph workflow with intent classification
-  **Knowledge Base** - 90+ support topics across 4 categories
-  **RAG Pipeline** - Semantic search with Chroma vector database
-  **Local Mode** - No OpenAI API required (uses MockLLM)

**Tech Stack:** Python 3.11+, FastAPI, LangChain, LangGraph, Streamlit, Chroma, sentence-transformers

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Streamlit UI (Port 8501)                   â”‚
â”‚   Chat â€¢ Feedback Buttons â€¢ Cache Indicators â€¢ Session ID    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP/REST (with session_id)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI Backend (Port 8000)                  â”‚
â”‚  /query â€¢ /feedback â€¢ /analytics/* â€¢ /session/* â€¢ /cache/*   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼            â–¼            â–¼             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Query  â”‚  â”‚Conversationâ”‚ â”‚Feedback â”‚  â”‚LangGraphâ”‚
   â”‚  Cache  â”‚  â”‚  Memory   â”‚ â”‚Collectorâ”‚  â”‚Workflow â”‚
   â”‚  (LRU)  â”‚  â”‚(Sessions) â”‚ â”‚(Analytics)â”‚ â”‚ Router  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚             â”‚                           â”‚
        â”‚             â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚         â–¼
        â”‚             â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚    â”‚Retriever â”‚
        â”‚             â”‚    â”‚ + LLM    â”‚
        â”‚             â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â–¼             â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Chroma  â”‚   â”‚MockLLM/â”‚
                          â”‚VectorDB  â”‚   â”‚   HF   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Request Flow with New Features**

```
User Query (with session_id)
    â†“
[1] Check Query Cache
    â”œâ”€â†’ Cache HIT â†’ Return cached response (< 0.1s)
    â””â”€â†’ Cache MISS â†’ Continue
            â†“
[2] Get/Create Conversation Session
            â†“
[3] Check if Follow-up Question
    â”œâ”€â†’ Yes â†’ Inject conversation context
    â””â”€â†’ No â†’ Process normally
            â†“
[4] Relevance Check
    â”œâ”€â†’ Out-of-scope â†’ Return guidance message
    â””â”€â†’ In-scope
            â†“
[5] Intent Classification (Workflow)
            â†“
[6] Document Retrieval (Vector DB)
            â†“
[7] Answer Generation (LLM)
            â†“
[8] Confidence Scoring
            â†“
[9] Should Cache?
    â””â”€â†’ High confidence (â‰¥0.6) + Not escalated â†’ Add to cache
            â†“
[10] Update Conversation Memory
            â†“
[11] Return Answer + Metadata
            â†“
[Optional] User Provides Feedback
            â†“
[12] Store in Feedback Collector
            â†“
[13] Analytics & Improvement Insights
```

---

## ğŸš€ Quick Start


### **1. Clone and Install**

```bash
git clone https://github.com/kcteja18/Customer-Support-Orchestrator.git
cd Customer-Support-Orchestrator

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt
```

### **2. Ingest Knowledge Base**

```bash
python scripts/manage.py ingest
```

### **3. Run the Application**

**Option A: Development Mode**

```bash
# Terminal 1: Start Backend
python backend/main.py

# Terminal 2: Start UI
streamlit run src/ui/app.py
```

**Option B: Using Docker**

```bash
docker-compose up --build
```

### **4. Access the Application**

- **UI**: http://localhost:8501
- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

---

## ğŸ“– API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check with cache stats |
| `/query` | POST | Process query with caching & memory |
| `/ingest` | POST | Ingest documents (background) |
| `/feedback` | POST | Submit user feedback |
| `/analytics/feedback` | GET | Get feedback analytics |
| `/analytics/cache` | GET | Get cache performance stats |
| `/cache/clear` | POST | Clear query cache |
| `/session/{id}/history` | GET | Get conversation history |
| `/session/{id}` | DELETE | Clear session |

---

## ğŸ§ª Testing

```bash
# Quick test
python scripts/manage.py query "How do I reset my password?"

# Run all tests
python scripts/manage.py test

# Or use pytest
pytest tests/ -v
```

**Test Queries:**
- âœ… In-scope: "How do I reset my password?", "What payment methods?"
- âŒ Out-of-scope: "What's the weather?", "Tell me a joke"

---

## ğŸ“ Project Structure

```
Customer-Support-Orchestrator/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py                   # FastAPI app with all endpoints
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ agents.py             # Support orchestrator & MockLLM
â”‚   â”‚   â”œâ”€â”€ cache.py              # Query caching (NEW)
â”‚   â”‚   â”œâ”€â”€ memory.py             # Conversation memory (NEW)
â”‚   â”‚   â”œâ”€â”€ feedback.py           # Feedback collector (NEW)
â”‚   â”‚   â”œâ”€â”€ graph.py              # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ retriever.py          # Chroma vector store
â”‚   â”‚   â”œâ”€â”€ ingest.py             # Document ingestion
â”‚   â”‚   â””â”€â”€ embeddings.py         # sentence-transformers
â”‚   â””â”€â”€ ui/
â”‚       â””â”€â”€ app.py                # Streamlit UI
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ manage.py                 # Management CLI
â”œâ”€â”€ examples/data/                # Knowledge base (4 .md files)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

Create `.env` file:

```env
LLM_MODE=local                           # or "hf" for HuggingFace
HUGGINGFACE_API_TOKEN=your_token_here    # Optional
LOG_LEVEL=INFO
```

**Customize in `src/config.py`:**
- Cache TTL (default: 60 minutes)
- Max cache size (default: 1000 entries)
- Conversation memory (default: 10 messages)
- Confidence threshold (default: 0.7)

---

## ğŸ”„ Workflow

```
User Query â†’ Cache Check â†’ Session Management â†’ Follow-up Detection
                â†“
     Intent Classification â†’ Document Retrieval â†’ Answer Generation
                â†“
     Confidence Scoring â†’ Cache Decision â†’ Update Memory â†’ Return
```

**Workflow features:**
- Intent-based routing (technical, billing, general)
- Automatic escalation for low confidence (<40%)
- Out-of-scope detection
- Source document tracking

---

## ğŸ› ï¸ Management CLI

```bash
# System information
python scripts/manage.py info

# Test query with documents
python scripts/manage.py query "How do I reset password?" --show-docs

# Clear and reingest documents
python scripts/manage.py clear --confirm
python scripts/manage.py ingest

# Run tests
python scripts/manage.py test
```

---

## ğŸ³ Docker Deployment

```bash
# Build and start
docker-compose up --build -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

---

## ğŸ“Š Features

### Conversation Memory
- Maintains context across queries
- Detects follow-up questions
- Exports conversation history

### Query Caching
- LRU cache with TTL
- Query normalization
- Performance tracking

### Feedback System
- 5-star rating system
- Analytics dashboard
- Improvement suggestions

---

## ğŸ”§ Troubleshooting

| Issue | Solution |
|-------|----------|
| Cache not working | Check cache initialization and confidence threshold (â‰¥0.6) |
| Memory not persisting | Ensure consistent session IDs across requests |
| Feedback not saving | Verify `data/` directory exists and is writable |
| Vector store errors | Run `python scripts/manage.py clear --confirm` then reingest |
| Import errors | Install all dependencies: `pip install -r requirements.txt` |

---

## ğŸ¤ Contributing

Contributions welcome! Feel free to:
- Fork and customize
- Add new features
- Improve documentation
- Submit pull requests

---

## ğŸ“ License

MIT License - free to use in your own projects!

---

##  Acknowledgments

Built with: [LangChain](https://langchain.com/) â€¢ [LangGraph](https://langchain-ai.github.io/langgraph/) â€¢ [FastAPI](https://fastapi.tiangolo.com/) â€¢ [Streamlit](https://streamlit.io/) â€¢ [Chroma](https://www.trychroma.com/) â€¢ [sentence-transformers](https://www.sbert.net/)

---

<div align="center">

**â­ Star this repo if you find it helpful!**


</div>
